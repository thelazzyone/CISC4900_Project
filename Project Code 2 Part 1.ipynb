{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CISC 4900 First Interim Report - Eddie Lam.pdf', 'CombinedRows.csv', 'EditingDataset_V3.java', 'featMat.csv', 'featMatVersion2_10.csv', 'featMatVersion2_5.csv', 'featMatVersion2_6.csv', 'featMatVersion2_7.csv', 'featMatVersion2_8.csv', 'featMatVersion2_9.csv', 'features', 'Old dataset', 'Test_dataset.csv', 'Touchalytics-ProjectDef.pdf', 'Train_dataset.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "\n",
    "'''\n",
    "Reusing code:\n",
    "https://stackabuse.com/k-nearest-neighbors-algorithm-in-python-and-scikit-learn/\n",
    "\n",
    "Explaining result:\n",
    "https://datascience.stackexchange.com/questions/65839/macro-average-and-weighted-average-meaning-in-classification-report\n",
    "\n",
    "\n",
    "Test_fearMat_Clean: 4168\n",
    "    Before edit: 4231 rows × 34 columns\n",
    "    After edit: 4168 rows × 34 columns\n",
    "    \n",
    "    #removed 6 to 7\n",
    "    total = 3749         (20% = 750; 80% = 2,999)\n",
    "    \n",
    "\n",
    "Train_fearMat_Clean: 16680\n",
    "    Before edit: 16927 rows × 34 columns\n",
    "    After edit: 16680 rows × 34 columns\n",
    "    \n",
    "    #removed 6 to 7\n",
    "    total = 15045         (20% = 3,009; 80% = 12,036)\n",
    "\n",
    "'''\n",
    "\n",
    "import os\n",
    "#print(os.listdir(r\"C:\\Users\\eddie\\OneDrive\\Desktop\\CISC 4900\"))         #print out what's in the file/directory\n",
    "\n",
    "#train = pd.read_csv(r\"C:\\Users\\eddie\\OneDrive\\Desktop\\CISC 4900\\featMatVersion2_10.csv\")         #using test\n",
    "\n",
    "\n",
    "print(os.listdir(r\".\"))         #print out what's in the file/directory\n",
    "train = pd.read_csv(r\"featMatVersion2_10.csv\")\n",
    "\n",
    "\n",
    "#train = pd.read_csv(r\"Test_dataset.csv\")         #using test\n",
    "#test = pd.read_csv(r\"C:\\Users\\eddie\\OneDrive\\Desktop\\CISC 4900\\Train_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isnan(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isfinite(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the columns\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints the amount of users in 'User_ID'\n",
    "train['User_ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing the columns for X\n",
    "#Not using 'User_ID', 'Doc_ID', or 'Phone_ID'\n",
    "X = train[['Inter-Stroke time', 'Stroke Duration', 'Start X', 'Start Y', 'Stop X', 'Stop Y', 'Direct end-to-end Distance',\n",
    "        'Mean resulant length', 'WSAD Flag', 'Direction of end-to-end Time', '20 per pairwise velocity', \n",
    "        '50 per pairwise velocity', '80 per pairwise velocity', '20 per pairwise acc', '50 per pairwise acc', \n",
    "        '80 per pairwise acc', 'Median velocity at last 3pts', 'Largest deviation from end-to-end line', '20 per dev line',\n",
    "        '50 per dev line', '80 per dev line', 'Average Direction', 'Length of Trajectory', \n",
    "        'Ratio dist and length of trajectory', 'Average velocity', 'Median acceleration at first 5 pts',\n",
    "        'Mid-Stroke pressure', 'Mid-Stroke area covered', 'Mid-Stroke finger orientation', 'Change of finger orientation',\n",
    "        'Phone orientation']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing the lables for y\n",
    "y = train['User_ID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and test split\n",
    "#80% train, 20% test\n",
    "#splitting the data into test and train dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training and Prediction\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)         #value for k\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make prediction on the test data\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 66   0   0 ...   0   0   0]\n",
      " [  0 204   0 ...   1   0   0]\n",
      " [  3   1  64 ...   0   0   0]\n",
      " ...\n",
      " [  0   5   1 ...  29   0   0]\n",
      " [  0   0   4 ...   0  31   0]\n",
      " [  1   1   0 ...   1   0  33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.73      0.71        90\n",
      "           2       0.73      0.87      0.79       235\n",
      "           3       0.43      0.39      0.41       166\n",
      "           4       0.63      0.69      0.65        54\n",
      "           5       0.46      0.58      0.51        90\n",
      "           6       0.54      0.68      0.60       103\n",
      "           7       0.57      0.57      0.57       121\n",
      "           8       0.54      0.66      0.60       113\n",
      "           9       0.60      0.80      0.69        76\n",
      "          10       0.58      0.47      0.52        80\n",
      "          11       0.51      0.72      0.60        75\n",
      "          12       0.73      0.74      0.74        66\n",
      "          13       0.56      0.35      0.44        62\n",
      "          14       0.65      0.86      0.74       130\n",
      "          15       0.68      0.74      0.71       142\n",
      "          16       0.44      0.44      0.44        93\n",
      "          17       0.56      0.65      0.60       144\n",
      "          18       0.70      0.66      0.68        88\n",
      "          19       0.61      0.53      0.57        74\n",
      "          20       0.53      0.59      0.56        59\n",
      "          21       0.72      0.67      0.70       132\n",
      "          22       0.66      0.57      0.61        84\n",
      "          23       0.68      0.77      0.72       197\n",
      "          24       0.64      0.61      0.62        87\n",
      "          25       0.76      0.55      0.64        95\n",
      "          26       0.68      0.40      0.50        53\n",
      "          27       0.62      0.42      0.50       127\n",
      "          28       0.68      0.53      0.60       139\n",
      "          29       0.84      0.74      0.79        87\n",
      "          30       0.64      0.48      0.55        48\n",
      "          31       0.67      0.62      0.64        74\n",
      "          32       0.76      0.78      0.77        58\n",
      "          33       0.86      0.65      0.74       137\n",
      "          34       0.87      0.97      0.92       131\n",
      "          35       0.60      0.69      0.64       197\n",
      "          36       0.80      0.62      0.70       107\n",
      "          37       0.57      0.56      0.57        82\n",
      "          38       0.70      0.67      0.69       158\n",
      "          39       0.47      0.41      0.44        71\n",
      "          40       0.58      0.46      0.52        67\n",
      "          41       0.92      0.82      0.87        40\n",
      "\n",
      "    accuracy                           0.64      4232\n",
      "   macro avg       0.65      0.63      0.63      4232\n",
      "weighted avg       0.65      0.64      0.64      4232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the Algorithm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 66   0   0   2   0   0   5   0   0   0   0   0   0   0   1   0   0   0\n",
      "    0   2   0   3   2   0   1   0   0   4   0   2   0   0   0   1   0   1\n",
      "    0   0   0   0   0]\n",
      " [  0 204   0   0   1   0   1   0   1   0   0   0   0   0   3   0   0   0\n",
      "    0   1   0   2   4   4   2   0   1   4   1   0   0   0   0   0   0   2\n",
      "    0   3   1   0   0]\n",
      " [  3   1  64   0   2   7   0   4   0   4   6   2   0   0   0   7  20   9\n",
      "    4   0   7   0   0   0   0   0   7   0   0   0   0   1   0   0  14   0\n",
      "    4   0   0   0   0]\n",
      " [  0   2   0  37   3   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
      "    0   1   0   0   1   0   0   0   0   1   0   0   0   0   1   4   0   0\n",
      "    0   1   1   0   1]\n",
      " [  0   1   7   0  52   0   0   3  10   1   0   2   0   1   0   0   1   0\n",
      "    3   0   0   0   0   2   0   0   3   0   0   0   0   1   0   0   1   0\n",
      "    2   0   0   0   0]\n",
      " [  0   1   1   0   2  70   0   4   0   0   3   0   2   0   0   6   2   0\n",
      "    1   0   2   0   0   0   0   0   2   1   0   0   1   0   0   0   3   0\n",
      "    2   0   0   0   0]\n",
      " [  9   9   2   2   1   1  69   0   0   0   0   0   0   0   2   0   1   0\n",
      "    0   1   0   7   2   1   1   1   0   4   0   1   0   0   0   3   0   0\n",
      "    0   3   1   0   0]\n",
      " [  0   0   3   0   6   2   0  75   1   1   2   3   1   0   2   1   0   0\n",
      "    1   0   1   0   2   0   0   0   1   0   0   0   0   0   1   0   3   0\n",
      "    3   0   0   4   0]\n",
      " [  0   0   1   0   3   0   0   1  61   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   1   1   0   0   3   0   0   0   0   1   0   0   1   1\n",
      "    0   0   0   2   0]\n",
      " [  0   0   6   0   1   0   0   2   0  38  10   0   0   0   0   4   3   1\n",
      "    3   1   5   0   0   0   1   0   1   0   0   0   0   0   0   0   1   0\n",
      "    0   0   0   3   0]\n",
      " [  0   0   2   0   1   1   1   1   0   2  54   0   0   0   0   0   1   1\n",
      "    2   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   5   0\n",
      "    0   0   0   2   0]\n",
      " [  0   1   3   0   3   0   0   3   0   0   1  49   0   0   0   1   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   1\n",
      "    2   0   0   1   0]\n",
      " [  1   0   1   0   0   6   0   6   0   0   2   0  22   0   0   3   4   2\n",
      "    0   0   0   0   0   1   0   0   1   0   0   0   0   0   0   0   4   0\n",
      "    5   0   2   2   0]\n",
      " [  0   0   0   0   0   1   0   1   0   0   0   0   0 112   0   0   0   0\n",
      "    0   0   0   0   7   0   0   0   0   0   1   0   7   0   0   0   0   1\n",
      "    0   0   0   0   0]\n",
      " [  1   2   0   1   0   0   2   0   0   1   0   0   1   2 105   0   0   0\n",
      "    0   0   0   0  18   0   0   1   0   0   0   0   1   0   2   0   0   4\n",
      "    0   1   0   0   0]\n",
      " [  0   0   6   0   2   6   0   5   0   3   4   1   0   0   0  41   6   2\n",
      "    0   0   2   0   1   0   0   0   1   1   1   0   0   3   0   0   5   0\n",
      "    2   0   0   1   0]\n",
      " [  0   0   7   0   0   5   1   5   0   0   3   1   0   2   0   8  93   2\n",
      "    1   0   1   0   1   0   0   0   2   0   0   0   0   0   0   0  11   0\n",
      "    0   0   0   1   0]\n",
      " [  0   0   2   1   0   2   0   0   0   1   3   0   0   0   0   1   7  58\n",
      "    0   1   5   0   0   0   0   0   1   0   0   0   0   1   0   0   2   0\n",
      "    0   0   0   3   0]\n",
      " [  1   1   2   0   8   2   0   1   0   3   2   0   0   0   1   1   2   3\n",
      "   39   0   0   0   0   0   2   0   2   0   0   0   0   1   0   0   2   0\n",
      "    0   0   0   1   0]\n",
      " [  1   4   0   0   0   0   0   1   0   1   0   0   0   0   3   0   0   0\n",
      "    0  35   1   1   1   1   0   0   0   5   0   0   0   0   0   0   0   0\n",
      "    0   2   3   0   0]\n",
      " [  0   0   6   0   3   0   0   0   0   1   7   4   0   0   1   1   3   0\n",
      "    1   0  89   0   0   0   0   0   0   0   0   0   0   0   0   0  15   0\n",
      "    1   0   0   0   0]\n",
      " [  3   3   0   0   0   0  12   1   1   0   0   0   2   0   1   0   0   0\n",
      "    0   0   0  48   1   1   1   0   0   4   0   0   0   0   0   1   0   0\n",
      "    0   0   5   0   0]\n",
      " [  0   6   0   1   2   0   2   0   2   0   0   0   0   4  22   0   0   0\n",
      "    0   0   0   0 151   0   1   1   0   0   0   0   2   0   1   0   0   1\n",
      "    0   1   0   0   0]\n",
      " [  3   1   2   2   1   1   1   0   0   0   1   0   0   0   1   0   0   0\n",
      "    0   2   0   2   4  53   0   0   0   1   0   1   1   0   1   1   0   0\n",
      "    0   6   2   0   0]\n",
      " [  2  11   2   2   1   0   1   0   2   1   0   0   0   0   2   0   1   0\n",
      "    1   3   0   0   1   0  52   2   0   3   0   0   0   0   1   1   2   0\n",
      "    0   2   0   0   2]\n",
      " [  0   0   1   1   2   1   4   0   0   0   0   0   2   0   0   0   0   0\n",
      "    0   0   0   2   3   2   0  21   0   1   0   6   0   0   0   0   0   1\n",
      "    0   3   3   0   0]\n",
      " [  0   2  10   0   4   8   0   3   8   2   0   0   2   0   0   8  10   0\n",
      "    2   0   2   0   1   0   0   0  53   1   0   0   0   4   0   0   7   0\n",
      "    0   0   0   0   0]\n",
      " [  0  18   1   0   2   2   9   2   2   0   0   0   0   0   0   0   0   1\n",
      "    1   9   0   1   0   5   0   0   0  74   2   0   0   0   0   3   0   0\n",
      "    0   3   4   0   0]\n",
      " [  0   0   0   0   3   0   0   1   1   0   0   0   0  10   1   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0  64   0   2   0   4   0   0   0\n",
      "    0   1   0   0   0]\n",
      " [  2   0   0   7   2   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   2   0   2   0   0   3   3   0   1   0  23   0   0   0   0   0   0\n",
      "    0   1   1   0   0]\n",
      " [  1   0   1   0   0   0   0   0   0   0   0   0   0  22   2   0   0   0\n",
      "    0   0   0   0   2   0   0   0   0   0   0   0  46   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   1   0   1   1   0   1   1   1   1   0   0   0   0   0   1   0\n",
      "    1   1   0   0   0   0   0   0   1   0   0   0   0  45   0   0   0   0\n",
      "    2   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   2   3   0   0   2   3  14   2   0   1   0\n",
      "    0   0   0   0   2   0   2   0   0   0   2   1   8   0  89   1   0   3\n",
      "    0   0   1   0   0]\n",
      " [  1   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 127   0   0\n",
      "    0   2   0   0   0]\n",
      " [  0   0   9   0   1   8   0   1   0   3   4   0   0   0   0   7   4   2\n",
      "    2   0   6   0   0   0   0   0   6   0   0   0   0   0   0   0 135   0\n",
      "    7   1   1   0   0]\n",
      " [  0   1   1   1   0   1   0   3   1   0   0   0   0   3   2   0   0   0\n",
      "    0   1   0   0   8   4   1   0   0   0   5   0   0   0   2   0   0  66\n",
      "    1   6   0   0   0]\n",
      " [  0   0   1   0   1   2   0   4   1   1   2   3   1   0   0   3   3   1\n",
      "    1   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   9   0\n",
      "   46   0   0   2   0]\n",
      " [  0   6   1   1   3   0   8   2   0   0   0   0   0   0   0   0   0   0\n",
      "    0   1   0   0   9   4   0   2   0   2   0   1   0   0   0   4   0   0\n",
      "    1 106   7   0   0]\n",
      " [  0   5   1   0   0   0   5   0   0   0   0   0   1   0   3   1   0   0\n",
      "    0   2   0   5   0   4   1   0   0   1   0   1   0   0   1   0   2   0\n",
      "    1   8  29   0   0]\n",
      " [  0   0   4   1   3   1   0   6   5   1   0   0   2   1   1   0   2   1\n",
      "    1   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   2   1\n",
      "    1   1   0  31   0]\n",
      " [  1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   3   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
      "    0   0   1   0  33]]\n"
     ]
    }
   ],
   "source": [
    "#prints the entire confusion matrix\n",
    "#however, it doesnn't fit the entire row and loops around\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "resultCM = (confusion_matrix(y_test, y_pred))\n",
    "print(resultCM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.73      0.71        90\n",
      "           2       0.73      0.87      0.79       235\n",
      "           3       0.43      0.39      0.41       166\n",
      "           4       0.63      0.69      0.65        54\n",
      "           5       0.46      0.58      0.51        90\n",
      "           6       0.54      0.68      0.60       103\n",
      "           7       0.57      0.57      0.57       121\n",
      "           8       0.54      0.66      0.60       113\n",
      "           9       0.60      0.80      0.69        76\n",
      "          10       0.58      0.47      0.52        80\n",
      "          11       0.51      0.72      0.60        75\n",
      "          12       0.73      0.74      0.74        66\n",
      "          13       0.56      0.35      0.44        62\n",
      "          14       0.65      0.86      0.74       130\n",
      "          15       0.68      0.74      0.71       142\n",
      "          16       0.44      0.44      0.44        93\n",
      "          17       0.56      0.65      0.60       144\n",
      "          18       0.70      0.66      0.68        88\n",
      "          19       0.61      0.53      0.57        74\n",
      "          20       0.53      0.59      0.56        59\n",
      "          21       0.72      0.67      0.70       132\n",
      "          22       0.66      0.57      0.61        84\n",
      "          23       0.68      0.77      0.72       197\n",
      "          24       0.64      0.61      0.62        87\n",
      "          25       0.76      0.55      0.64        95\n",
      "          26       0.68      0.40      0.50        53\n",
      "          27       0.62      0.42      0.50       127\n",
      "          28       0.68      0.53      0.60       139\n",
      "          29       0.84      0.74      0.79        87\n",
      "          30       0.64      0.48      0.55        48\n",
      "          31       0.67      0.62      0.64        74\n",
      "          32       0.76      0.78      0.77        58\n",
      "          33       0.86      0.65      0.74       137\n",
      "          34       0.87      0.97      0.92       131\n",
      "          35       0.60      0.69      0.64       197\n",
      "          36       0.80      0.62      0.70       107\n",
      "          37       0.57      0.56      0.57        82\n",
      "          38       0.70      0.67      0.69       158\n",
      "          39       0.47      0.41      0.44        71\n",
      "          40       0.58      0.46      0.52        67\n",
      "          41       0.92      0.82      0.87        40\n",
      "\n",
      "    accuracy                           0.64      4232\n",
      "   macro avg       0.65      0.63      0.63      4232\n",
      "weighted avg       0.65      0.64      0.64      4232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultCR = (classification_report(y_test, y_pred))\n",
    "print(resultCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "'macro':\n",
    " Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "\n",
    "'weighted':\n",
    " Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label).\n",
    " This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
